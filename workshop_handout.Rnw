\documentclass{article} %\documentclass[a4paper,12pt,twoside]{memoir}
%\usepackage{btp}
%
% Example Workshop Handout with title page and a section demonstrating
% the different environments defined in the top matter


% if trainermanual is true, then include extra info in the report
\newif\iftrainermanual
\trainermanualtrue

\usepackage{url}
% Set some Workshop specific info
\iftrainermanual
\title{TRAINER MANUAL for R and rqtl workshop}
\else
\title{Introductory workshop for R and rqtl}
\fi
\date{May 2014}
\author{Angus Wallace}



\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
%\setWorkshopTitle{Introductory R workshop, rqtl}
%\setWorkshopVenue{ACPFG}
%\setWorkshopDate{May 2014}
%\setWorkshopAuthor{Angus Wallace}

%% this document can be rendered in R by typing:
%		CODEDIR <- Sys.getenv("CODEDIR")
%		DATADIR <- Sys.getenv("DATADIR")
%		setwd("~/R_workshop_handout/")
%		library(knitr)
%		Sys.setenv(TEXINPUTS=getwd(),
%				     BIBINPUTS=getwd(),
%				     BSTINPUTS=getwd())
%		knit2pdf("~/R_workshop_handout/workshop_handout.Rnw", output=paste(DATADIR,"/pdfs/R_workshop_handout.tex",sep=""))

<<setup, echo=FALSE, include=FALSE, cache=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
CODEDIR <- Sys.getenv("CODEDIR")
DATADIR <- Sys.getenv("DATADIR")
library(xtable)
library(reshape)
library(plyr)
library(stringr)
library(made4)
options(width=60)
@



%
% Workshop Title Page
%
%\workshoptitlepage

\section{This workshop}
\subsection{Aims}
Brief introduction to R\\
Basic use

\begin{enumerate}
\item{fundamental use}
\item{data types}
\item{read in data}
\item{quality-check and visualise data}
\item{write out data}
\item{rqtl}
\end{enumerate}
\section{How to read this document}

Each section in this workshop introduces a new concept or tool. Each section contains some examples and is followed by some problems for you to work through to cement your understanding. The facilitators are here to help you with these. It's hopefully clear that the purpose of these problems is to understand them, rather than get the "correct" pattern of letters and numbers on the screen!

\subsection{Code}
To use R, one must write code. This document contains code for different purposes, and it is formatted in a characteristic and consistent way throughout.
<<code_eg, eval=TRUE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# boxes like this contain example code

# comments start with a hash 
# (like this line, which is not run)
print("this line has no hash at the start, so is run")

# Also, note that output generated by R has a double-comment

# There are three kinds of problems for you to attempt:
@

\subsubsection{Write some code! (aka problems)}
<<ex_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# You should attempt to acheive all problems in green
@

<<ex_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 
# If you are progressing well, attempt problems in orange also (as an extension)
@

<<ex_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# Problems in Purple are designed to be difficult. These are problems you might want to think about later.
@

\iftrainermanual
\subsubsection{Trainer solutions}
<<ex_soln, eval=TRUE, cache=TRUE, result='asis', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# Trainer solutions to the problems are included in (uncoloured) plaintext
@
\fi

\part{Working in R}
\section{Fundamentals}
\subsection{Arithmetic}
One can use R just like a calculator, to do basic arithmetic:

<<arithmetic, eval=TRUE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
1+1
2*4
3^4
exp(3)         # e to the power of 3
pi*(2.5^2)     # area of a circle
tan(0.5)       # trigonometry
@

\subsection{Functions}
Definition:
R uses \textit{functions} to get things done. Think of them as tools.
The functions are collated into \textit{libraries} (aka \textit{packages}) that can be loaded when needed. Think of them as toolboxes.
For example, in the same way that a carpenter may keep all their chisels together in a toolbox, a particular R library/package might contain functions to allow the plotting of data. \\
It is possible to write functions for commonly performed activities, and this is very useful (and acheivable!), but it is outside the scope of this workshop.

\subsection{Using libraries}
So, libraries/packages contain collections of functions, which are what get things done. When one first opens R, the \textit{base} library is automatically loaded, and provides the fundamental functions. \\
The following code shows the installation and loading of a library

<<libraries, eval=TRUE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# install a package
install.packages("ggplot2")
# load the package
library(ggplot2)

# note that when installing, one needs to quote the package name, but when loading it one does not 
@

\subsection{Getting help}
You will do this constantly!
Most functions in R have a help page that explains how to use the function. One can access this by typing (eg.) \\
?ggplot\\

(a question mark, followed by the function name. Note that the function's library must be loaded first)

I generally use Google, but be warned -- because its name is so short, "R" is a difficult term to search for -- try to be specific


\section{Data types}
R has different ways of storing data, that are appropriate for different uses.
\subsection{The vector type}

<<vector, eval=TRUE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# a is a numeric vector
a <- c(1,2,3,4,5)
a

# R can do vector arithmetic
a + 1
a * 2
2 ^ a

# vectors can be split into components by indexing
# get the first element of the vector
a[1]   

# get the first three elements of the vector
a[1:3] 

# get all the elements of the vector except the second
a[-2]  

# replace the second element of the vector
a[2] <- 10
a

# try replacing it with something else
a[2] <- "10"
a
# the vector has been changed ("cast") to a character vector (note that 10, above, is quoted), and can no longer be used for arithmetic
a + 1

# Oops! It can be changed back though, using a function:
as.numeric(a) + 1
@

%%% PROBLEMS
\subsubsection{Write some code!}
<<vector_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. Create a vector of length 5, containing any integers you like

# 2. get the 3rd element and store it in another vector

# 3. get all the elements except the 3rd, and store them in another vector
@

<<vector_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 
# 4. take the vectors created in steps 2. and 3. and combine them into a new vector 

# 5. take the vector created in 1., and create a new vector that is the same except that the 2nd and 4th values are replaced with -99

# 6. find the sum of all the elements of the vector from 1.

# 7. use the vector created in 5., find the sum of its elements squared

# 7b. use the vector created in 5., find the sum of its elements, except the -99s, squared 
@

<<vector_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 8. read the help for the function "seq", and use it to create a vector containing the values 0 to 99 in increments of three (eg 0, 3, 6, 9....)

# 9. from the vector created in step 8., make a vector containing all the values that are multiples of two
# hint -- explore the modulo function, %%, read help('%%')
@

%%% SOLUTIONS
\iftrainermanual
\subsubsection{Trainer solutions}
<<vector_soln, eval=FALSE, cache=TRUE, result='asis', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# Trainer solutions to the problems are included in plaintext
# 1 
a <- c(1, 2, 3, 4, 5)
length(a)

# 2
b <- a[3]

# 3
c <- a[-3]

# 4
d <- c(b, c)

# 5
a99 <- a
a99[c(2, 4)] <- -99

# 6
sum(a)

# 7
sum(a99^2)

# 7b
sum(a99[a99 != -99]^2)

# 8
f <- seq(0, 99, 3)

# 9
g <- f[f %% 2 == 0]
@
\fi

\subsection{The list type}
Vectors must be all one \textit{type} of data -- eg. numeric, character, boolean. Lists do not have this restriction, and can mix types of data

<<list, eval=TRUE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
my_list <- list("I", "have", 10, "cars")

# one can even put a vector inside a list (a is the numeric vector from before)
my_list[[5]] <- a

# getting a subset of a list is similar to a vector, but notice the double brackets
my_list[[3]]

#...but it can get tricky
my_list[[5]][1:2]
@

%%% PROBLEMS
\subsubsection{Write some code!}

<<list_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. 
@

<<list_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 
# 4. 
@

<<list_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 
@

%%% SOLUTIONS
\iftrainermanual
\subsubsection{Trainer solutions}
<<list_soln, eval=TRUE, cache=TRUE, result='asis', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# Trainer solutions to the problems are included in plaintext
@
\fi

\subsection{The data.frame type}
data.frames are great. They are ideal for storing and manipulating experimental data. Think of them as a spreadsheet, where columns can contain different types of data. Data can be sliced and diced in many ways, and it is easy to aggregate the data too.

<<data_frame, eval=TRUE, fig.width=3, fig.height=3, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
cultivar <- c("RAC","RAC","RAC","EXCAL","EXCAL","EXCAL","EXCAL")
height   <- c( 0.6 ,0.57 ,0.62 , 0.92  , 0.77  , 0.55  , 0.76  )
drought  <- c(FALSE,TRUE, TRUE , FALSE , TRUE  , TRUE  , FALSE )
df <- data.frame(cultivar, height,drought)
df
names(df)
row.names(df)
dim(df)
nrow(df)
ncol(df)
# we've made a small data.frame with three columns and seven rows. How can we split the data?

# by address (get rows 1 and 2, and columns 1 to 3)
df[1:2,1:3]

# get all the height data
df$height

# get everything except the third column
df[,-3]
df[,c("cultivar", "height")]
df[,1:2]

# get the drought data only and drop the third column
df[df$drought,-3]

# visualise the data
library(ggplot2)
ggplot(df, aes(cultivar, height)) + geom_point() + facet_wrap(~drought)

@

%%% PROBLEMS
\subsubsection{Write some code!}
<<df_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. there is a data.frame called mtcars -- look at it
# Note: if you break the mtcars data somehow, you can reload/reset it by typing
data(mtcars)

# 2. create a table counting the number of cars with different number of cylinders (hint: use the "table" function)

# 3. plot a histogram of the milage of the cars (hint: use the "hist" function)

# 4. calculate the mean hp of the 4, 6 and 8 cylinder cars separately (hint: use the "mean" function). Try to find at least three different ways of subsetting the data.frame

@

<<df_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 
# 5. create a scatterplot of mpg vs hp (hint: use the "plot" function)

# 6. for each car, calculate the hp to cyl ratio (horse-power per cylinder: a very important quantity!), store it in a new column in the dataframe called "hp2cyl"

# 7. It has been found that the cars' weight was overestimated by 5% for cars weighing more than 3.5 tons -- correct this
@

<<df_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 8. install the "plyr" library, and repeat what you did in step 4 using the function ddply, a function in that library

# 9. install the "ggplot2" library, and explore different visualisations of the data
@

%%% SOLUTIONS
\iftrainermanual
\subsubsection{Trainer solutions}
<<df_soln, eval=FALSE, cache=TRUE, result='asis', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. there is a data.frame called mtcars -- look at it
mtcars

# 2. create a table counting the number of cars with different number of cylinders (hint: use the "table" function)
table(mtcars$cyl)

# 3. plot a histogram of the milage of the cars (hint: use the "hist" function)
hist(mtcars$mpg)

# 4. calculate the mean hp of the 4, 6 and 8 cylinder cars separately (hint: use the "mean" function). Note the different ways of addressing the data frame -- this should be emphasised to course attendees
mean(mtcars[mtcars$cyl==4,]$hp)
mean(mtcars$hp[mtcars[,"cyl"]==6])
mean(mtcars[mtcars[,2]==8,"hp"])

# 5. create a scatterplot of mpg vs hp (hint: use the "plot" function)
plot(mtcars$mpg, mtcars$hp)

# 6. for each car, calculate the hp to cylinder ratio (horse-power per cylinder: a very important quantity!), store it in a new column in the dataframe called "hp2cyl"
mtcars$hp2cyl <- mtcars$hp / mtcars$cyl

# 7. It has been found that the cars' weight was overestimated by 5% for cars weighing more than 3.5 tons -- correct this
overweight_cars <- mtcars$wt > 3.5
mtcars$wt[overweight_cars] <- mtcars$wt[overweight_cars] / 1.05

# 8. install the "plyr" library, and repeat what you did in step 4 using the function ddply, a function in that library
install.packages("plyr")
library(plyr)
ddply(mtcars, .(cyl), function(x) mean(x$hp))

# 9. install the "ggplot2" library, and explore different visualisations of the data
p <- ggplot(mtcars, aes(wt, mpg))
p <- p + geom_point(aes(size = qsec, colour=hp, shape=factor(cyl))) +
         scale_colour_gradient(low = "blue", high="red") +
         ggtitle("a 5-dimensional graph")
print(p)

@
\fi

\section{How to read in data}
This is nice, but we don't want to type in data by hand. Usually, we have data in a spreadsheet that we want to analyse. The way to get these data into R is as follows:

In a spreadsheet program, export the data in csv\footnote{comma-separated values} format. Some programs give the option to control the formatting, which depends on the data. Although csv files are nominally separated by a comma, one can choose any symbol -- use a symbol that does \textit{not} exist in your data: some good options are [\(, ; : | /\)] -- but one should definitely avoid \$ and \textbackslash. You may have the option to enclose any strings (writing) in quotation marks. That can be helpful, though I generally don't bother. \\

The exact way one reads in the data is determined by the format of your csv file. eg,

\texttt{\\
sample, cultivar, height, tillers, grain, group\\
1,      RAC,      3.25,   5,       4,     drought\\
2,      EXCAL,    3.25,   5,       4,     drought\\
3,      RAC,      3.25,   5,       4,     control\\
4,      EXCAL,    3.25,   5,       4,     control}
Then you would read it in with the command:
<<csv_read_1, eval=FALSE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
my.data.frame <- read.table(filename, header=TRUE, sep=",", 
                            stringsAsFactors=FALSE)
@
\textit{(Note that factors are a type of data that we have not discussed and are out of scope for this workshop. Avoid them for now.)}

Alternatively, if the csv file looked like this:\\
\texttt{\\
"sample"  "cultivar"  "height"  "tillers"  "grain"  "group"\\
1       "RAC"       3.25    5        4      "drought"\\
2       "EXCAL"     3.25    5        4      "drought"\\
3       "RAC"       3.25    5        4      "control"\\
4       "EXCAL"     3.25    5        4      "control"\\
}\\
Then you would read it in with the command:
<<csv_2, eval=FALSE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
my.data.frame <- read.table(filename, header=TRUE, sep=" ", quote="\"", stringsAsFactors=FALSE)
@

The idea here, is that we have a quote symbol within quotes. In other words, we tell R which character denotes a quotation. Because the quotation character itself has special meaning to R, we have to tell R that we really mean the character and are not just finishing the quotation. We do this by putting a backslash in front of the character. This is also called "escaping" the character. If we just had three quote symbols in a row (without the backslash) R would think we were opening and closing a quotation, and then opening another -- the second one would never be closed, which would cause an error.

%%% PROBLEMS
\subsubsection{Write some code!}

%% generate the csv file:
% plex_dat <- read.table("~/R_workshop_handout/TA44.dat", header=TRUE, quote="\"")
% plex_dat$affy <- gsub("_[0-9]{7}","",row.names(plex_dat))
% plex_dat <- plex_dat[!duplicated(plex_dat$affy),]
% row.names(plex_dat) <- plex_dat$affy
% plex_dat <- plex_dat[!duplicated(plex_dat$affy),]
% plex_dat <- plex_dat[,-25]
% write.table(plex_dat,file="~/R_workshop_handout/plex_dat.dat")

<<readin_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# There is a csv file that you can read. It is located at [SHOW LOCATION HERE]. 

# 1. Open this file in RStudio, using [FILE -> Open File]
# in the menu. This will open the file in a text-editor within  
# RStudio so that its contents and formatting can be viewed.

# 2. Read in the file, using read.table, to a new variable.

# 3. make a list of the column names

# 4. make a list of the first 10 row names

# 5. Calculate the difference, at each sample, between rows 1 and 2

# 6. Plot the data in row 5 (use the plot and lines functions)

# 7. use read.cross to read in the qtl.dat file
@

<<readin_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 
# 7. list and plot all the data for probe "Ta.10026.1.A1_at"

# 8. create a histogram of the data in column "X2.WL711.susceptible.irrigated"
@

<<readin_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
   
@
%%% SOLUTIONS
\iftrainermanual
\subsubsection{Trainer solutions}
<<readin_soln, eval=FALSE, cache=TRUE, result='hide', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. 

# 2. Read in the file, using read.table, to a new variable.
plex_dat <- read.table("~/R_workshop_handout/plex_dat.dat", header=TRUE, quote="\"")

# 3. Make a list of the column names
names(plex_dat)

# 4. Make a list of the first 10 row names
row.names(plex_dat)[1:10]

# 5. Calculate the difference, at each sample, between rows 1 and 2
t(plex_dat[1,] - plex_dat[2,])

# 6. Plot the data in row 5
plot(t(plex_dat[5,]))
lines(t(plex_dat[5,]))

# 7. list and plot all the data for probe "Ta.10026.1.A1_at"
data <- plex_dat[row.names(plex_dat) == "Ta.10026.1.A1_at",]
plot(t(plex_dat[row.names(plex_dat) == "Ta.10026.1.A1_at",]))
lines(t(plex_dat[row.names(plex_dat) == "Ta.10026.1.A1_at",]))

# 8. create a histogram of the data in column "X2.WL711.susceptible.irrigated"
data <- plex_dat$"X2.WL711.susceptible.irrigated"
hist(plex_dat$"X2.WL711.susceptible.irrigated")

@
\fi

\part{rQTL}
\section{Installation}
To install rqtl, type \texttt{install.packages('qtl')}.
This package has been augmented by Julian Taylor -- one installs his add-on package by typing \texttt{install.packages('qtlPlus')}.

\section{Reading data into rqtl}
The rqtl package includes a function, \texttt{read.cross} that is designed to read a specially-formatted file containing qtl data, ready for analysis. When using read.cross, one must supply it with parameters that control its working.
\begin{enumerate}
\item{\texttt{file = "exmapOut.csv"} -- which file to load}
\item{\texttt{format = "csvr"} -- format of the file}
\item{\texttt{genotypes = c("AA", "BB")} -- they way the genotypes are labelled}
\item{\texttt{na.strings = c("-")} -- how missing data are labelled}
\item{\texttt{map.function = "kosambi"} -- how the mapping is performed}
\item{\texttt{estimate.map = FALSE} -- whether to estimate the map}
\end{enumerate}
More information can be found by typing \texttt{?read.cross} in R.

\subsection{Reading-in and interrogating qtl data}
\texttt{read.cross} produces a complicated "object"\footnote{we have talked about several objects in this workshop: lists, vectors, data.frames. What we haven't talked about, and what is out-of-scope, is that it is possible to create custom objects. Normally, a custom object will consist of a list of other objects, or a list of lists of other objects, etc... This exploits the fact that different objects can be mixed within a list}. With a small object, \texttt{str} can be useful to understand its internal structure, but that is less useful here because this object is too large.

<<qtl_1, eval=FALSE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
library(qtl)
library(qtlPlus)

# accessing the linkage map from the package
data(exmap, package = "qtlPlus")

# reading it in from a file
# there are a lot of potential arguments for this function but from experience users will require something
# similar to what I have below everytime

exmap <- read.cross(file = "qtl.dat", format = "csvr", genotypes = c("AA", "BB"), na.strings = c("-"), map.function = "kosambi", estimate.map = FALSE)

# printed breakdown of object
exmap


# number of markers on linkage groups
# number of linkage groups
# number of individuals
nmar(exmap)
nchr(exmap)
nind(exmap)

# structure of object is a list with two elements "pheno and "geno"
names(exmap)

# The "pheno" element is a data frame of phenotypes including a column of genotype names
# The "Genotype" column in the data frame SHOULD be a factor with levels equivalent ot the line names
exmap$pheno
names(exmap$pheno)
is.data.frame(exmap$pheno)
str(exmap$pheno)

# The geno element contains the linkage groups
names(exmap$geno)
names(exmap$geno$"1A")
str(exmap$geno$"1A")

# Each linkage group has two elements, "map" and "data".For each linkage group, the length of the "map"
# and the number of columns of the "data" will match each other. The rows exactly line up with the names
# in exmap$pheno$Genotype. R/qtl DOES NOT put row names on the data.
# looking at the marker data
head(exmap$geno$"1A"$data)
dim(exmap$geno$"1A"$data)
exmap$geno$"1A"$data[,"1A.m.10"]
dimnames(exmap$geno$"1A"$data)

# by default, R/qtl sets the allele codes as AA = 1, BB = 2. The object also has a class structure
class(exmap)

# the "bc" component of this cross represents a "backcross" so R/qtl knows this is a simple crossing
# of two parents (R/qtl handles more difficult crosses that are not discussed here).
@

Note that when one types \texttt{exmap} (or whatever one has called the object) the object's contents are not printed -- just a summary of them.

%%% PROBLEMS
\subsection{Write some code!}
<<qtl_1_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. Install and load the required function libraries


# 2. read in qtl.dat using read.cross
exmap <- read.cross(file = "qtl.dat", format = "csvr", genotypes = c("AA", "BB"), na.strings = c("-"), map.function = "kosambi", estimate.map = FALSE)

# 3. How many individuals have any missing marker data?

@

<<qtl_1_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 

@

<<qtl_1_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# nothing
@

%%% SOLUTIONS
\iftrainermanual
\subsection{Trainer solutions}
<<qtl_1_soln, eval=FALSE, cache=TRUE, result='asis', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. Install and load the required function libraries
install.packages("qtl")
install.packages("qtlPlus")
@

\subsection{Subsetting qtl data}
<<qtl_2, eval=FALSE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# subsetting your data to linkage group to first three linkage groups
# this can be done in multiple different ways
names(exmap$geno)

# 1. By explicitly naming the linkage groups
exmaps <- subset(exmap, chr = c("1A","1B1","1B2"))
nmar(exmaps)

# 2. By using the names of the "geno" part of the object
exmaps <- subset(exmap, chr = names(exmap$geno)[1:3])
nmar(exmaps)

# 3. By setting up a logical vector
wchr <- names(exmap$geno) %in% names(exmap$geno)[1:3]
wchr
exmaps <- subset(exmap, chr = wchr)
nmar(exmaps)

# subsetting your data to linkage groups OTHER THAN the first three linkage groups,
exmaps <- subset(exmap, chr = !(names(exmap$geno) %in% names(exmap$geno)[1:3]))
nmar(exmaps)

# you can actually subset the map yourself without using R/qtl subset() command
exmaps <- exmap
exmaps$geno <- exmap$geno[1:3]
exmaps$geno <- exmap$geno[c("1A","1B1","1B2")]
nmar(exmaps)

exmapf <- exmap
exmapf$geno <- exmap$geno[4:length(exmap$geno)]
nmar(exmapf)

# and you can even put them back together
exmaps$geno <- c(exmapf$geno, exmaps$geno)
exmaps$geno <- exmap$geno[mixedorder(names(exmap$geno))]
nmar(exmaps)

### Subsetting individuals (i.e. removing genotypes from data)

# removing first three genotypes
# this can be done multiple ways

# 1. Stating numerically which ones to drop
exmaps <- subset(exmap, ind = -(1:3))
nind(exmaps)

# 2. Stating logically which ones to drop
whind <- !(exmap$pheno$Genotype %in% exmap$pheno$Genotype[1:3])
whind
exmaps <- subset(exmap, ind = whind)
nind(exmaps)

@

%%% PROBLEMS
\subsection{Write some code!}
<<qtl_2_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 1. Create a new map that contains only marker data for the 1* chromasomes.

# 2. Create a new map that contains only individuals without any missing marker data

@

<<qtl_2_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 

# 2. Find any individuals possessing any markers that are not double haploid, and remove them from the object


@

<<qtl_2_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# 4. Find any individuals possessing a phenotype that is more than 4 standard deviations from the mean and, remove them. (useful functions: var, sqrt)
@

%%% SOLUTIONS
\iftrainermanual
\subsection{Trainer solutions}
<<qtl_2_soln, eval=TRUE, cache=TRUE, result='asis', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# nothing
@

\subsection{Other interrogation, modification and subsetting tools}
<<qtl_3, eval=FALSE, cache=TRUE, result='asis', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# pull "map" component from each chromosome
pm <- pull.map(exmap)
pm

# check map of "1A" linkage groups
pm[["1A"]]

# drop markers and return object.
exmap$geno$"1A"$map
exmapd <- drop.markers(exmap, c("1A.m.1","1A.m.2"))
exmapd$geno$"1A"$map

# move marker from what linkage group to another and return object 
# (places marker at end of linkage group).
# this moves marker "1A.m1.1" to the end of linkage group "1B".
exmapm <- movemarker(exmap, "1A.m.1","1B")

# this switches the numeric values of the marker "1A.m.1" 
# (i.e. 1 becomes 2 and 2 becomes 1)
exmapm <- switchAlleles(exmap, "1A.m.1")

# returns chromosome and cm position of markers (find marker positions)
find.markerpos(exmap, c("1A.m.1","2A.m.7"))

### more advanced operations

# remove individuals with large recombination
countXO(map)
countXO(exmap)[countXO(exmap) > 40]
ct <- countXO(exmap) < 40
exmaps <- subset(exmap, ind = ct)

# reverse orientation of a linkage group
exmaps <- exmap
exmaps$geno$"1A"$map <- rev(exmaps$geno$"1A"$map)
exmaps$geno$"1A"$map <- abs(exmaps$geno$"1A"$map - exmaps$geno$"1A"$map[1])
exmaps$geno$"1A"$data <- exmaps$geno$"1A"$data[,ncol(exmaps$geno$"1A"$data):1]

# breaking linkage groups (qtlPlus function, see ?breakCross)
exmaps <- breakCross(exmap, split = list("1A" = "1A.m.4"))
nmar(exmaps)

# merging linkage groups (qtlPlus function, see ?mergeCross)
exmapz <- mergeCross(exmaps, merge = list("1A" = c("1A1","1A2")))
nmar(exmapz)
exmapz$geno$"1A"$map

# order linkage groups (uses mixedorder() from library gtools)
exmap$geno <- exmap$geno[mixedorder(names(exmap$geno))]


@

%%% PROBLEMS
\subsection{Write some code!}
<<qtl_3_work1, eval=TRUE, cache=TRUE, result='asis', background='#A7F7A7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
#nothing
@

<<qtl_3_work2, eval=TRUE, cache=TRUE, result='asis', background='#FfC7B9', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>= 

# find any markers with missing data in 4 or more individuals and remove them

@

<<qtl_3_work3, eval=TRUE, cache=TRUE, result='asis', background='#F7C5C7', tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# nothing
@

%%% SOLUTIONS
\iftrainermanual
\subsection{Trainer solutions}
<<qtl_3_soln, eval=TRUE, cache=TRUE, result='asis', background='#F9F9FF', highlight=FALSE, tidy=TRUE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=60)>>=
# nothing
@





\section{Appendix}
\subsection{Installing R and RStudio}
On MS Windows, there are two steps:
\begin{enumerate}
\item{download \textit{R} from \url{http://cran.r-project.org/bin/windows/base/} and install it. }
\item{download \textit{RStudio desktop} from \url{https://www.rstudio.com/ide/download/} and install it}
\end{enumerate}

\end{document}
